{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0da6119-1e66-4b77-bb33-b75314d2fd80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Common\n",
    "\n",
    "These sections include code common to both ResNet and Inception."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71401c1-e4bb-473c-9089-b9f664be480a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "Let's setup and configure dependencies. Note that since torchviz is used, graphviz needs to be specially installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee8ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import contextlib\n",
    "from functools import lru_cache\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import random\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms as T\n",
    "from torchviz import make_dot # This requires external downloads as well\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b1d91ed-5a91-4f62-bc7f-31bfa59a65bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    Sets the seed of the worker to depend on the initial seed. Credit to\n",
    "    https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "# For DataLoaders\n",
    "g = torch.Generator().manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2045b5-74a7-41b8-b0be-2da5d6e6dfbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare progress bar\n",
    "tqdm_variant = tqdm.tqdm # Assume not in Jupyter\n",
    "try:\n",
    "    # Credit https://stackoverflow.com/a/39662359\n",
    "    shell_name = get_ipython().__class__.__name__\n",
    "    if shell_name == \"ZMQInteractiveShell\":\n",
    "        # Case in Jupyter\n",
    "        tqdm_variant = tqdm.notebook.tqdm\n",
    "except NameError:\n",
    "    # Probably no iPhython instance, just use standard\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e58de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bfad3-b97c-4938-88da-43e47951e9e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plotting and Debugging Tools\n",
    "\n",
    "Let's create some helpful functions for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e861da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Steven's ModelExamples\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57feb0c1-18ca-4346-a620-a26030a7877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_dist(\n",
    "    baseline_observations,\n",
    "    stabilized_observations\n",
    "):\n",
    "    \"\"\"Plot our reproduction of Figure 7.\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Cumulative Distributions\")\n",
    "    ax.set_xlabel(\"Feature Distance\", fontweight=\"bold\", loc=\"left\")\n",
    "    ax.set_ylabel(\"Cumulative Fraction\", fontweight=\"bold\", loc=\"top\")\n",
    "    ax.hist(\n",
    "        baseline_observations,\n",
    "        round(np.sqrt(len(baseline_observations))),\n",
    "        density=True,\n",
    "        histtype=\"step\",\n",
    "        cumulative=True,\n",
    "        label=\"Baseline\"\n",
    "    )\n",
    "    if len(stabilized_observations) > 0:\n",
    "        ax.hist(\n",
    "            stabilized_observations,\n",
    "            round(np.sqrt(len(stabilized_observations))),\n",
    "            density=True,\n",
    "            histtype=\"step\",\n",
    "            cumulative=True,\n",
    "            label=\"Stabilized\"\n",
    "        )\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.tick_params(axis=\"x\", direction=\"in\", pad=-15)\n",
    "    ax.tick_params(axis=\"y\", direction=\"in\", pad=-22)\n",
    "    ax.set_yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "    ax.set_yticklabels(\n",
    "        [\"20%\",\"40%\",\"60%\",\"80%\",\"100%\"],\n",
    "        {\"fontweight\" : \"bold\", \"verticalalignment\" : \"top\"}\n",
    "    )\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.grid()\n",
    "    fig.savefig(\n",
    "        os.path.join(\n",
    "            os.path.abspath(\"\"),\n",
    "            f\"cumulative_dists_{int(time.time()) % 1000000:06}.png\"\n",
    "        )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17edab80-3391-4fd6-977d-635f89910893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_first_triplet(queries, positives, negatives):\n",
    "    a, b, c = queries[0], positives[0], negatives[0]\n",
    "    ToPIL = T.ToPILImage() # Converting function\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    ax[0].imshow(ToPIL(a))\n",
    "    ax[1].imshow(ToPIL(b))\n",
    "    ax[2].imshow(ToPIL(c))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64bfaafa-c819-4b54-9609-11bdec012522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def debug_distances(triplet_ranking_model, batch, item_idx=0):\n",
    "    with torch.no_grad():\n",
    "        output = triplet_ranking_model(*map(lambda x : x.to(device), batch))\n",
    "        qfeat = output[item_idx][0]\n",
    "        pfeat = output[item_idx][1]\n",
    "        nfeat = output[item_idx][2]\n",
    "        pos_dist = torch.sqrt(((qfeat - pfeat)**2).sum()).item()\n",
    "        neg_dist = torch.sqrt(((qfeat - nfeat)**2).sum()).item()\n",
    "        print(f\"Distance to positive: {pos_dist}, to negative: {neg_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d1391-758e-4863-bc80-e6394e21cac8",
   "metadata": {},
   "source": [
    "This part is also helpful for storing results of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab9f248-96b3-43bc-bf1a-7e45d4c33a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _def_save_filename(iteration_number : int, is_model : bool):\n",
    "    \"\"\"\n",
    "    Returns a save filename from an iteration number, and whether the\n",
    "    thing being saved is the model or the loss progress.\n",
    "    \"\"\"\n",
    "    # Make sure inputs are okay (no directory traversal attacks!)\n",
    "    if not isinstance(iteration_number, int):\n",
    "        raise TypeError(\"Iteration number should be an integer.\")\n",
    "\n",
    "    # Retrieve proper name\n",
    "    if is_model:\n",
    "        return os.path.join(\n",
    "            os.path.dirname(os.path.abspath(\"\")),\n",
    "            f\"model_save_{iteration_number}_{int(time.time())%1000000:06}.pt\"\n",
    "        )\n",
    "    return os.path.join(\n",
    "        os.path.dirname(os.path.abspath(\"\")),\n",
    "        f\"progress_save_{iteration_number}_{int(time.time())%1000000:06}.pt\"\n",
    "    )\n",
    "\n",
    "#\n",
    "# This class will make recording information easier\n",
    "#\n",
    "class TrainResult:\n",
    "    \"\"\"\n",
    "    Hold the results of a training round. Basically a nice wrapper.\n",
    "\n",
    "    Losses and accuracies should be averages over a batch for plot\n",
    "    labels to make sense.\n",
    "\n",
    "    Use whichever storage makes sense, but if one doesn't use the\n",
    "    storage then don't expect the corresponding plots to do anything.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        \"\"\"\n",
    "        Constructor - prepare local variables. Include model since the\n",
    "        one provided to trainer will likely be moved to a different\n",
    "        device. Provide the one that is actually trained here, and then\n",
    "        it can be used.\n",
    "        \"\"\"\n",
    "        self.train_loss_history = []\n",
    "        self.val_loss_history = []\n",
    "        self.train_accuracy_history = []\n",
    "        self.val_accuracy_history = []\n",
    "        self.time_training = 0.0\n",
    "        self.time_validating = 0.0\n",
    "        self.model = model\n",
    "\n",
    "    def plot_loss_train_valid_curves(self, ax, show_legend : bool=True):\n",
    "        \"\"\"Use matplotlib to show training curves. Supply axis in ax.\"\"\"\n",
    "        ax.plot(self.train_loss_history, label=\"Train\")\n",
    "        ax.plot(self.val_loss_history, label=\"Test\")\n",
    "        ax.set_title(f\"Model Loss\")\n",
    "        ax.set_xlabel(\"Iteration\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        if show_legend:\n",
    "            ax.legend()\n",
    "\n",
    "    def plot_accuracy_train_valid_curves(self, ax, show_legend=True):\n",
    "        \"\"\"Use matplotlib to show training curves. Supply axis in ax.\"\"\"\n",
    "        ax.plot(self.train_accuracy_history, label=\"Train\")\n",
    "        ax.plot(self.val_accuracy_history, label=\"Test\")\n",
    "        ax.set_title(f\"Model Accuracy\")\n",
    "        ax.set_xlabel(\"Iteration\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        if show_legend:\n",
    "            ax.legend()\n",
    "\n",
    "    def print_time_info(self):\n",
    "        \"\"\"Prints some lines with information about timing.\"\"\"\n",
    "        print(f\"Spent {round(self.time_training)} seconds training.\")\n",
    "        print(f\"Spent {round(self.time_validating)} seconds evaluating.\")\n",
    "\n",
    "    def full_analysis(self, axs):\n",
    "        \"\"\"Display all analysis plots and print time information.\"\"\"\n",
    "        if len(self.train_loss_history) > 0:\n",
    "            self.plot_loss_train_valid_curves(axs[0])\n",
    "        if len(self.train_accuracy_history) > 0:\n",
    "            self.plot_accuracy_train_valid_curves(axs[1])\n",
    "        if self.time_training > 0.0:\n",
    "            self.print_time_info()\n",
    "\n",
    "    def save(self, save_filename_func, count : int=0):\n",
    "        \"\"\"\n",
    "        Uses the save_filename_func provided with the count to create\n",
    "        files that save the models current weights and the training\n",
    "        progress so far.\n",
    "\n",
    "        For count, 0 is by convention the final version.\n",
    "        \"\"\"\n",
    "        # Save model\n",
    "        torch.save(self.model.state_dict(), save_filename_func(count, True))\n",
    "        # Save progress\n",
    "        with open(save_filename_func(count, False), \"wb\") as file_obj:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"train_loss_history\" : self.train_loss_history,\n",
    "                    \"val_loss_history\" : self.val_loss_history,\n",
    "                    \"train_accuracy_history\" : self.train_accuracy_history,\n",
    "                    \"val_accuracy_history\" : self.val_accuracy_history,\n",
    "                    \"time_training\" : self.time_training,\n",
    "                    \"time_validating\" : self.time_validating\n",
    "                }, file_obj\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c28b7a-20d1-41b8-9d6d-33b0c38946f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiments\n",
    "\n",
    "Let's make some functions to run experiments on models.\n",
    "\n",
    "For the following, see how closely the triplet ranking models think compressed versions of the same images are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f5e7fb-1544-4321-bba1-49c814249271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_observations(baseline_model, stabilized_model, imagefolder):\n",
    "    \"\"\"\n",
    "    Given a model trained for triplet ranking, make duplicate detection\n",
    "    observations.\n",
    "    \"\"\"\n",
    "    baseline_observations = []\n",
    "    stabilized_observations = []\n",
    "    tensor_transform = inception_transform\n",
    "    \n",
    "    for img_name in tqdm_variant(os.listdir(imagefolder)):\n",
    "        #\n",
    "        # Deal with images\n",
    "        #\n",
    "        image_fpath = os.path.join(imagefolder, img_name)\n",
    "        if \"jpeg\" in img_name.lower():\n",
    "            original_img = Image.open(image_fpath).convert(\"RGB\")\n",
    "        else:\n",
    "            continue\n",
    "        # Thanks https://stackoverflow.com/a/30771751\n",
    "        buffer = BytesIO()\n",
    "        original_img.save(buffer, \"JPEG\", optimize=True, quality=50)\n",
    "        compressed_img = Image.open(buffer).convert(\"RGB\")\n",
    "        \n",
    "        orig_tensor = tensor_transform(original_img)\n",
    "        comp_tensor = tensor_transform(compressed_img)\n",
    "        orig_tensor = orig_tensor.view(1, *orig_tensor.shape)\n",
    "        comp_tensor = comp_tensor.view(1, *comp_tensor.shape)\n",
    "        #\n",
    "        # Make observations\n",
    "        #\n",
    "        baseline_model.eval()\n",
    "        if stabilized_model is not None:\n",
    "            stabilized_model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Baseline\n",
    "            original_rep = nn.functional.normalize(baseline_model(orig_tensor))\n",
    "            compressed_rep = nn.functional.normalize(baseline_model(comp_tensor))\n",
    "            dist = torch.sqrt(((original_rep - compressed_rep)**2).sum())\n",
    "            baseline_observations.append(dist)\n",
    "            # Stabilized\n",
    "            if stabilized_model is not None:\n",
    "                original_rep = nn.functional.normalize(stabilized_model(orig_tensor))\n",
    "                compressed_rep = nn.functional.normalize(stabilized_model(comp_tensor))\n",
    "                dist = torch.sqrt(((original_rep - compressed_rep)**2).sum())\n",
    "                stabilized_observations.append(dist)\n",
    "            \n",
    "    return baseline_observations, stabilized_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a88619-4546-4161-ba5d-00e08f826ae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Models\n",
    "\n",
    "We'll similarly create model objects as we go along, but this section contains things that simplify making them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac837e-f76f-4125-b3d9-6ac6b9b86898",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "968864a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit https://discuss.pytorch.org/t/how-to-add-noise-to-mnist-dataset-when-using-pytorch/59745\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return (\n",
    "            tensor\n",
    "            + torch.empty(tensor.size(), device=device).normal_() * self.std\n",
    "            + self.mean\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "366f9024-7be8-439c-8602-30c895b78433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies an amount of JPEG compression to a PIL image    \n",
    "class JPEGTransform(nn.Module):\n",
    "    def __init__(self, quality=50):\n",
    "        self.quality = quality\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        buffer = BytesIO()\n",
    "        img.save(buffer, \"JPEG\", optimize=True, quality=self.quality)\n",
    "        return Image.open(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebbbc6-0c37-46d6-ac09-4fc3251bf630",
   "metadata": {},
   "source": [
    "ResNet is made to be used with data transformed as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74886e62-5e7a-42b2-84fd-3f43dccac3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transform = T.Compose([\n",
    "    T.Resize((256,256)),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bdf3ad-faed-4137-957b-d21ac06f8b00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a52b46-8c49-4959-8f83-39a3851cad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletRanker(nn.Module):\n",
    "    \"\"\"Triplet ranking model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        \"\"\"Creates a triplet ranker out of the model.\"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "    def forward(self, queries, positives, negatives):\n",
    "        \"\"\"Send batch of triplets through.\"\"\"\n",
    "        queries_encode = nn.functional.normalize(self.model(queries))\n",
    "        positives_encode = nn.functional.normalize(self.model(positives))\n",
    "        negatives_encode = nn.functional.normalize(self.model(negatives))\n",
    "        return queries_encode, positives_encode, negatives_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e18b078d-5644-4d88-8ca2-7037dd224c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StabilityTrainingModel(torch.nn.Module):\n",
    "    def __init__(self, other_model, perturbation=None):\n",
    "        \"\"\"\n",
    "        Wraps another model to allow for stability training. May specify\n",
    "        custom perturbation transformation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = other_model\n",
    "        \n",
    "        if perturbation is None:\n",
    "            self.perturb = AddGaussianNoise(0, 0.04)\n",
    "        else:\n",
    "            self.perturb = perturbation\n",
    "    \n",
    "    def forward(self, *x):\n",
    "        \"\"\"Apply the model to some input.\"\"\"\n",
    "        return self.model(*x), self.model(*[self.perturb(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddc17e-bafe-46a1-9f12-b9a7b70476d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Datasets\n",
    "\n",
    "Let's prepare some datasets. First, we'll make a custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cedeaca-3215-46cb-a183-ce1b8b1c2dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: an alternative to this paradigm is loading all the images using\n",
    "# the transform as a catalogue onto main memory, then detach on access\n",
    "# TODO - refactor\n",
    "class TripletRankingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 img_dir : str,\n",
    "                 pos_per_img : int,\n",
    "                 neg_per_pos : int,\n",
    "                 transform=None,\n",
    "                 training=True\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Point at directory which has subdirectories corresponding to\n",
    "        each class. Supply the number of positive images per image in\n",
    "        the subdirectories and the number of negative images to combine\n",
    "        with.\n",
    "        \"\"\"\n",
    "        if transform is None:\n",
    "            transform = nn.Identity()\n",
    "        self.transform = transform\n",
    "        self.mode = \"RGB\"#ImageReadMode.RGB\n",
    "        \n",
    "        #\n",
    "        # Initialize triplets\n",
    "        #\n",
    "        self.triplets = [ ]\n",
    "        \n",
    "        if training:\n",
    "            self._train_init(img_dir, pos_per_img, neg_per_pos)\n",
    "        else:\n",
    "            self._val_init(img_dir, pos_per_img, neg_per_pos)\n",
    "        \n",
    "    def _train_init(self, img_dir, pos_per_img, neg_per_pos):\n",
    "        # Generate randoms first, index into later. Need to count\n",
    "        # Iterate over classes\n",
    "        class_names = os.listdir(img_dir)\n",
    "        if os.path.exists(os.path.join(img_dir, class_names[0], \"images\")):\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x, \"images\"),\n",
    "                class_names\n",
    "            ))\n",
    "        else:\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x),\n",
    "                class_names\n",
    "            ))\n",
    "        for subdir_path in subdirectories_paths:\n",
    "            img_per_class = len(os.listdir(subdir_path))\n",
    "            break\n",
    "        randoms = np.random.randint(\n",
    "            0,\n",
    "            img_per_class,\n",
    "            (\n",
    "                len(subdirectories_paths),\n",
    "                img_per_class,\n",
    "                pos_per_img,\n",
    "                neg_per_pos + 1 # Last for positive selection\n",
    "            ),\n",
    "            dtype=\"int16\"\n",
    "        )\n",
    "        \n",
    "        # TODO - this method inefficient, only need to hold 2 numbers,\n",
    "        # some string format info\n",
    "        # DANGER - potential for loops with symbolic/hard links\n",
    "        # Iterate over classes\n",
    "        for subdir_idx, subdir_path in enumerate(subdirectories_paths):\n",
    "            exclude_subdir_idx =  [\n",
    "                            *range(subdir_idx),\n",
    "                            *range(\n",
    "                                subdir_idx + 1,\n",
    "                                len(subdirectories_paths)\n",
    "                            )\n",
    "                        ]\n",
    "            # Iterate over images\n",
    "            for img_idx, img in enumerate(os.listdir(subdir_path)):\n",
    "                img_path = os.path.join(subdir_path, img)\n",
    "                # Iterate over alike images\n",
    "                for pos_it in range(pos_per_img):\n",
    "                    pos_rand = randoms[subdir_idx][img_idx][pos_it][-1]\n",
    "                    # Adjust on equal\n",
    "                    if pos_rand == pos_it:\n",
    "                        if pos_rand == 0:\n",
    "                            pos_rand += 1\n",
    "                        else:\n",
    "                            pos_rand -= 1\n",
    "                    # Form name\n",
    "                    pos_path = os.path.join(\n",
    "                        subdir_path,\n",
    "                        f\"{class_names[subdir_idx]}_{pos_rand}.JPEG\"\n",
    "                    )\n",
    "                    # Need more randoms for next step\n",
    "                    neg_class_rands = np.random.choice(\n",
    "                        exclude_subdir_idx,\n",
    "                        neg_per_pos,\n",
    "                        replace=True\n",
    "                    )\n",
    "                    # Iterate over dissimilar images\n",
    "                    for neg_it in range(neg_per_pos):\n",
    "                        class_rand = neg_class_rands[neg_it]\n",
    "                        neg_class_path = subdirectories_paths[class_rand]\n",
    "                        neg_class = class_names[class_rand]\n",
    "                        neg_rand = randoms[subdir_idx][img_idx][pos_it][neg_it]\n",
    "                        # Form name\n",
    "                        neg_path = os.path.join(\n",
    "                            neg_class_path,\n",
    "                            f\"{neg_class}_{neg_rand}.JPEG\"\n",
    "                        )\n",
    "                        # Append\n",
    "                        self.triplets.append((img_path, pos_path, neg_path))\n",
    "                        \n",
    "    def _val_init(self, img_dir, pos_per_img, neg_per_pos):\n",
    "        # Generate randoms first, index into later. Need to count\n",
    "        # Iterate over classes\n",
    "        class_names = os.listdir(img_dir)\n",
    "        \n",
    "        if os.path.exists(os.path.join(img_dir, class_names[0], \"images\")):\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x, \"images\"),\n",
    "                class_names\n",
    "            ))\n",
    "        else:\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x),\n",
    "                class_names\n",
    "            ))\n",
    "            \n",
    "        img_per_class = dict()\n",
    "        img_names = []\n",
    "        for idx in range(len(class_names)):\n",
    "            subdir_path = subdirectories_paths[idx]\n",
    "            class_name = class_names[idx]\n",
    "            img_names.append(list(os.listdir(subdir_path)))\n",
    "            img_per_class[class_name] = len(img_names[-1])\n",
    "        \n",
    "        # TODO - this method inefficient, only need to hold 2 numbers,\n",
    "        # some string format info\n",
    "        # DANGER - potential for loops with symbolic/hard links\n",
    "        # Iterate over classes\n",
    "        for subdir_idx, subdir_path in enumerate(subdirectories_paths):\n",
    "            exclude_subdir_idx =  [\n",
    "                            *range(subdir_idx),\n",
    "                            *range(\n",
    "                                subdir_idx + 1,\n",
    "                                len(subdirectories_paths)\n",
    "                            )\n",
    "                        ]\n",
    "            this_dir = img_names[subdir_idx]\n",
    "            # Iterate over images\n",
    "            for img_idx, img in enumerate(this_dir):\n",
    "                img_path = os.path.join(subdir_path, img)\n",
    "                # Iterate over alike images\n",
    "                for pos_it in range(pos_per_img):\n",
    "                    # Form name\n",
    "                    rand_idx = np.random.choice([\n",
    "                        *range(pos_it),\n",
    "                        *range(pos_it + 1, img_per_class[class_names[pos_it]])\n",
    "                    ])\n",
    "                    pos_name = this_dir[rand_idx]\n",
    "                    # Form path\n",
    "                    pos_path = os.path.join(subdir_path, pos_name)\n",
    "                    # Need more randoms for next step\n",
    "                    neg_class_rands = np.random.choice(\n",
    "                        exclude_subdir_idx,\n",
    "                        neg_per_pos,\n",
    "                        replace=True\n",
    "                    )\n",
    "                    # Iterate over dissimilar images\n",
    "                    for neg_it in range(neg_per_pos):\n",
    "                        class_rand = neg_class_rands[neg_it]\n",
    "                        neg_class_path = subdirectories_paths[class_rand]\n",
    "                        neg_class = class_names[class_rand]\n",
    "                        # Select from the directory\n",
    "                        neg_name = np.random.choice(img_names[class_rand])\n",
    "                        # Form name\n",
    "                        neg_path = os.path.join(neg_class_path, neg_name)\n",
    "                        # Append\n",
    "                        self.triplets.append((img_path, pos_path, neg_path))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        this_triplet = self.triplets[idx]\n",
    "        #query = self.transform(read_image(this_triplet[0], self.mode))\n",
    "        #positive = self.transform(read_image(this_triplet[1], self.mode))\n",
    "        #negative = self.transform(read_image(this_triplet[2], self.mode))\n",
    "        query = self.transform(Image.open(this_triplet[0]).convert(self.mode))\n",
    "        positive = self.transform(Image.open(this_triplet[1]).convert(self.mode))\n",
    "        negative = self.transform(Image.open(this_triplet[2]).convert(self.mode))\n",
    "        return query, positive, negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072591e9-090f-4209-9bfe-276c8e454834",
   "metadata": {},
   "source": [
    "The following is helpful to keep around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86997b7d-71ce-4e6f-9a5e-ef0725ee3271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.abspath(\"\"), \"tiny-imagenet-200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5476c-8950-422d-94f4-4832a86a3337",
   "metadata": {},
   "source": [
    "We'll create dataset objects as we go since they take up memory, but these are used across tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790dcd31-2c44-42dc-83a7-fba571ff6908",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training Functions\n",
    "\n",
    "Factoring some common patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77288ff1-6e0f-43e2-9780-e3e94312e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    loss_func,\n",
    "    result,\n",
    "    training=True\n",
    "):\n",
    "    loss = torch.Tensor([0])\n",
    "    avg_loss = 0\n",
    "    \n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    start = time.perf_counter()\n",
    "    with contextlib.ExitStack() as stack: # For validation/training\n",
    "        if not training:\n",
    "            stack.enter_context(torch.no_grad()) # No gradients\n",
    "        for queries, positives, negatives in tqdm_variant(\n",
    "            loader,\n",
    "            desc=f\"{'Training' if training else 'Validation'} Iteration\",\n",
    "            disable=False\n",
    "        ):\n",
    "            if training:\n",
    "                # Prepare optimizer\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Prepare relevant variables\n",
    "            queries = queries.to(device)\n",
    "            positives = positives.to(device)\n",
    "            negatives = negatives.to(device)\n",
    "            out = model(queries, positives, negatives)\n",
    "\n",
    "            # Determine loss\n",
    "            loss = loss_func(*out)\n",
    "\n",
    "            # Store intermediate results - note average over batch\n",
    "            item = loss.item()\n",
    "            avg_loss += item\n",
    "            if training:\n",
    "                result.train_loss_history.append(item)\n",
    "            else:\n",
    "                result.val_loss_history.append(item)\n",
    "\n",
    "            if training:\n",
    "                loss.backward() # Get gradients\n",
    "                optimizer.step() # Descend gradients\n",
    "    end = time.perf_counter()\n",
    "    if training:\n",
    "        result.time_training += end - start\n",
    "    else:\n",
    "        result.time_validating += end - start\n",
    "    \n",
    "    return avg_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17339d-2cce-4816-900c-334c521b48a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Miscellaneous Helpers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308c33d-d0f6-44b1-94a7-c81397a4d953",
   "metadata": {},
   "source": [
    "Some constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e03d5a6b-2e35-468c-80c1-a84c55c0de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of the stability objective\n",
    "ALPHA = 0.01\n",
    "\n",
    "CLASS_NUMBER = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cf73d-1082-4eb3-a09b-448647ae7fcf",
   "metadata": {},
   "source": [
    "These are common to multiple sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7fd03d4-574a-4005-aff8-9ee97c8a27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_transform = T.Compose([\n",
    "    T.Resize(299),\n",
    "    T.CenterCrop(299),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c02db2-d443-458b-af1d-c50503fe3c7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2817692-107e-45e3-864c-be2415e9bf49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Triplet Ranking\n",
    "\n",
    "Next, let's train some triplet ranking models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb75818-9c69-475d-8253-7313032d31d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Baseline\n",
    "\n",
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "295bbb05-f675-4758-bb81-380bb0535412",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(data_dir, \"train\")\n",
    "val_path = os.path.join(data_dir, \"val\")\n",
    "#trd = TripletRankingDataset(train_path, 2, 2, transform=inception_transform)\n",
    "trd_val = TripletRankingDataset(\n",
    "    val_path,\n",
    "    1,\n",
    "    1,\n",
    "    transform=inception_transform,\n",
    "    training=False\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "#tr_train_loader = torch.utils.data.DataLoader(trd, batch_size=batch_size,\n",
    "                                     #num_workers=0, shuffle=True)\n",
    "tr_val_loader = torch.utils.data.DataLoader(trd_val, batch_size=batch_size,\n",
    "                                     num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1052a4-34b8-45bb-9ae9-415f54a4f379",
   "metadata": {},
   "source": [
    "Prepare new model that maps into a 64 dimensional encoding space. Note that this is less than the 200 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bc9c288-38b5-46e4-8369-fd4ed63894b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_encoder = torchvision.models.inception_v3(\n",
    "    pretrained=True,\n",
    "    aux_logits=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfb84be9-931c-4efd-9c87-905bb01a9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set them all to frozen by default\n",
    "for param in inception_encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a362bd8-ab0f-48e3-8e15-763943303c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's thaw some layers\n",
    "for param in inception_encoder.Mixed_7c.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d6eef34-ceb4-4013-80b4-8c32cf11e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_encoder.fc = nn.Linear(2048, 64) # 64-Dimensional Encoding\n",
    "\n",
    "inception_triplet_ranking = TripletRanker(inception_encoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e6f56-63e3-4b0a-80c7-36f53491a64f",
   "metadata": {},
   "source": [
    "Training controllers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "927ea431-0742-4ac8-8a9f-c62646236287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#itr_optimizer = optim.SGD(inception_triplet_ranking.parameters(), lr=0.005)\n",
    "itr_optimizer = optim.Adam(\n",
    "    inception_triplet_ranking.parameters(),\n",
    "    lr=0.005,\n",
    "    betas=(0.8,0.99)\n",
    ")\n",
    "#itr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #itr_optimizer,\n",
    "    #factor=0.5,\n",
    "    #patience=2,\n",
    "    #threshold=0.1\n",
    "#)\n",
    "# May try OneCycleLR, annealers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0273ab-a247-467e-9b3b-ff130122a179",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fd01d61-13ef-456e-831a-f0db70cb85ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_result = TrainResult(inception_triplet_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951edae9-3311-475e-8ed0-dfde972eed1f",
   "metadata": {},
   "source": [
    "Triplet loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03db5694-d6ef-4eb7-81cc-075607ed7dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_loss = nn.TripletMarginLoss(1.0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8b91e-2958-4adb-b69c-da97725fa7b4",
   "metadata": {},
   "source": [
    "Training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91013b3e-77e2-4354-8c89-2b520225312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_best_loss = float(\"inf\")\n",
    "itr_best_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9872900-9439-46b1-b4bc-38474ab90cdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3b9b3a6d4b45ef8a654cde05368c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/15 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc9fa4913744ce3a068e035a34c1c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee65f5139e4d462ca546509bad9ebc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: Training Loss: 0.4004341648387909, Validation Loss: 0.3754558493963446\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d111f01eed3409599c825d8e8e1e76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6daad51bb8714674a2229ede6ab7cae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Training Loss: 0.3672840037536621, Validation Loss: 0.3674835697554361\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d29686b773b40879bd2ba5ea9f88d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4c7e4e9ca54a76934fd1e14a78b3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Training Loss: 0.34829089056015017, Validation Loss: 0.3664518064274765\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6453c0a3f23e4fd0b6692d7e342d609e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bc7381ea61479bb8e026a6efaea780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Training Loss: 0.33164853138923645, Validation Loss: 0.3645986601139029\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2282f4b97d1462ea193013c5311a70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fa4c694227447a993094f686a727cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Training Loss: 0.3178371453809738, Validation Loss: 0.36568494675496516\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faad93c2acf4a2f82b2a8feee5980f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f596d1f44ac45629beefedcac9c221b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Training Loss: 0.3075065079665184, Validation Loss: 0.36260136440634344\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cd6d2f04704bfa99afdf16de711bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae3f5a13c3c4e4fbb40a051ba94f8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Training Loss: 0.2971532835125923, Validation Loss: 0.3692831148902258\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5469367ef3d445fa40bfd4671fbe286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26392f78dd5143588126f18c707e4ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Training Loss: 0.2867655133199692, Validation Loss: 0.3667950142329684\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafa154d77c7413eac6104569d25c4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5f616601764237ae1b3ba159ed38f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Training Loss: 0.27496212601661685, Validation Loss: 0.37086490266762984\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf40690997914d1b92d3e4bcdd50227a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ba597ac1354cdf85c806ad84290259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Training Loss: 0.2666996761536598, Validation Loss: 0.37325120055542205\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceac920d4c4f4e939cfc5e9a1a68a677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9093bb112234d2ab934d76acea11864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Training Loss: 0.25871495096087455, Validation Loss: 0.36599684976779234\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880a2ac7adb54067b92c180d6e8f3223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dbb81617cb4ebea9c8a70fad95e45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: Training Loss: 0.24810040583372117, Validation Loss: 0.37677918007960337\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca37e2a2e744ecca1ee600cd3112f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7ce5d5e68140569f09a2e01153b226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: Training Loss: 0.24421424782514572, Validation Loss: 0.3685946888721789\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c265450eeea34bdf9ae4c0f88e632aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae0a03a67824edbad48a4593b702c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: Training Loss: 0.23393585928440094, Validation Loss: 0.3819884740458891\n",
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2f162fe01146d5bab7e91a6e02e93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f05f4917dcc4e3791cd27f7feaa71ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: Training Loss: 0.23031507392644882, Validation Loss: 0.38100931406640015\n"
     ]
    }
   ],
   "source": [
    "# Train for some number of epochs\n",
    "ITR_EPOCH_COUNT = 15 # with no normalization, + 16 + 1\n",
    "ITR_SAVE_PERIOD = 1\n",
    "\n",
    "loss = torch.Tensor([0])\n",
    "for epoch in tqdm_variant(\n",
    "    range(ITR_EPOCH_COUNT),\n",
    "    desc=f\"Epoch\",\n",
    "    unit=\"epoch\",\n",
    "    disable=False\n",
    "):\n",
    "    # For this training loop, we'll switch up the data each time.\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        del trd, tr_train_loader\n",
    "    except NameError:\n",
    "        pass\n",
    "    trd = TripletRankingDataset(train_path, 1, 1, transform=inception_transform)\n",
    "    tr_train_loader = torch.utils.data.DataLoader(trd, batch_size=batch_size,\n",
    "                                         num_workers=0, shuffle=True)\n",
    "    print(\"...done.\")\n",
    "    \n",
    "    # Debug learning rate\n",
    "    print(f\"Current Learning Rate: {itr_optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "    train_loss = triplet_epoch(\n",
    "        inception_triplet_ranking,\n",
    "        tr_train_loader,\n",
    "        itr_optimizer,\n",
    "        device,\n",
    "        itr_loss,\n",
    "        itr_result\n",
    "    )\n",
    "\n",
    "    val_loss = triplet_epoch(\n",
    "        inception_triplet_ranking,\n",
    "        tr_val_loader,\n",
    "        itr_optimizer,\n",
    "        device,\n",
    "        itr_loss,\n",
    "        itr_result,\n",
    "        training=False\n",
    "    )\n",
    "    \n",
    "    # Save a copy for safety\n",
    "    if val_loss < itr_best_loss:\n",
    "        torch.save(\n",
    "            inception_triplet_ranking, \n",
    "            os.path.join(\n",
    "                os.path.abspath(\"\"),\n",
    "                f\"best_itr_{itr_best_count}_{int(time.time()) % 1000000:06}.pt\"\n",
    "            )\n",
    "        )\n",
    "        itr_best_count += 1\n",
    "        itr_best_loss = val_loss\n",
    "        \n",
    "    if epoch % ITR_SAVE_PERIOD == ITR_SAVE_PERIOD - 1:\n",
    "        torch.save(\n",
    "            inception_triplet_ranking,\n",
    "            os.path.join(\n",
    "                os.path.abspath(\"\"),\n",
    "                f\"itr_{epoch}_{int(time.time()) % 1000000:06}.pt\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Print the last loss calculated and the epoch\n",
    "    print(f\"\\nEpoch {epoch}: Training Loss: {train_loss}, \" \\\n",
    "          f\"Validation Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760c4f0-b0cd-424a-8d2c-313eb7d2c887",
   "metadata": {},
   "source": [
    "Let's double check gradient calculations went well:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469b914-cf6f-4913-b4e3-cc73696721f5",
   "metadata": {},
   "source": [
    "The old way of saving is taking up lots of memory, let's just save the part that changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d96e338-3d54-471e-9f0a-5d1369fe5798",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    inception_triplet_ranking.model.state_dict(),\n",
    "    \"inception_triplet_ranking_2.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef73629c-decc-4eeb-9ad0-e3c596b797e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_result.save(_def_save_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0060721-78e4-41c6-89a0-1b80e97b6900",
   "metadata": {},
   "source": [
    "Let's also take a look at training/testing curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdad540a-1bae-4b4a-921a-ecbe31703872",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4uElEQVR4nO3dd3hUZfbA8e9JQhKqtFCkBRELKkUjKrgCIgii4rquir0ta91dXUXUXdtaUFdd24qo2H7WVVAUVGwYOgSk9xIg1BAgCSWQcn5/zM1kksxM7iSZTMr5PE8eZt773jvnoszJ+963iKpijDHGlCUq0gEYY4ypGSxhGGOMccUShjHGGFcsYRhjjHHFEoYxxhhXLGEYY4xxxRKGMeUkIokioiIS46LuDSIyoyriMiZcLGGYOkFEUkXkiIi0LFG+yPnST4xQaCElHmMiyRKGqUs2AiMK34jIKUD9yIVjTM1iCcPUJR8A1/m8vx5437eCiBwlIu+LSLqIbBKRf4hIlHMsWkT+LSK7RWQDMMzPuW+LyHYR2SoiT4hIdEUCFpGjRWSSiOwRkXUi8iefY71FJEVEskRkp4i84JTHi8j/iUiGiOwTkfki0roicRgDljBM3TIHaCIiJzpf5FcA/1eizivAUcAxQD88CeZG59ifgAuBXkAScFmJc98D8oBjnTqDgVsqGPPHQBpwtPN5T4nIQOfYS8BLqtoE6AJ85pRf79xDB6AFcCtwqIJxGGMJw9Q5ha2MQcAqYGvhAZ8k8oCqZqtqKvA8cK1T5XLgP6q6RVX3AE/7nNsaGAr8TVUPqOou4EXgyvIGKiIdgLOB+1U1R1UXAW/5xJMLHCsiLVV1v6rO8SlvARyrqvmqukBVs8obhzGFLGGYuuYD4CrgBkp0RwEtgVhgk0/ZJqCd8/poYEuJY4U6AfWA7U430D7gDaBVBWI9GtijqtkB4rkZOA5Y5XQ7XeiUfwB8D3wiIttE5FkRqVeBOIwBLGGYOkZVN+F5+H0BMKHE4d14fjvv5FPWkaJWyHY83Ty+xwptAQ4DLVW1qfPTRFVPqkC424DmItLYXzyqulZVR+BJSs8An4tIQ1XNVdXHVLUb0AdPN9p1GFNBljBMXXQzcK6qHvAtVNV8PM8BnhSRxiLSCbiHouccnwF/EZH2ItIMGO1z7nZgKvC8iDQRkSgR6SIi/UKIK855YB0vIvF4EsMs4GmnrLsT+4cAInKNiCSoagGwz7lGvogMEJFTnC62LDxJMD+EOIzxyxKGqXNUdb2qpgQ4fBdwANgAzAA+AsY7x97E09WzGFhI6RbKdXi6tFYAe4HPgbYhhLYfz8Ppwp9z8QwDTsTT2pgIPKKqPzj1hwDLRWQ/ngfgV6pqDtDG+ewsYCXwK6Uf7hsTMrENlIwxxrhhLQxjjDGuWMIwxhjjiiUMY4wxrljCMMYY40qtWh2zZcuWmpiYGOkwjDGmxliwYMFuVU1wU7dWJYzExERSUgKNljTGGFOSiGwqu5ZH2LqkRKSDiPwiIitFZLmI/NVPHRGRl51VOJeIyKk+x4aIyGrn2OiS5xpjjKla4XyGkQf8XVVPBM4E7hCRbiXqDAW6Oj8jgdfBuwjca87xbsAIP+caY4ypQmFLGKq6XVUXOq+z8cw4bVei2nDgffWYAzQVkbZAb2Cdqm5Q1SPAJ05dY4wxEVIlzzCc7S97AXNLHGpH8dU/05wyf+VnBLj2SDytEzp27OivijHG+JWbm0taWho5OTmRDiXs4uPjad++PfXqlX/h4rAnDBFpBHyBZ5+Akmvyi59TNEh56ULVccA4gKSkJFvnxBjjWlpaGo0bNyYxMRERf187tYOqkpGRQVpaGp07dy73dcI6D8NZg/8L4ENVLblQG3haDr7LRbfHs8haoHJjjKk0OTk5tGjRolYnCwARoUWLFhVuSYVzlJQAbwMrVfWFANUmAdc5o6XOBDKdZaLnA11FpLOIxOLZtWxSuGI1xtRdtT1ZFKqM+wxnl1RfPFtJLhWRRU7ZgzibzqjqWGAKno1s1gEHcfZOVtU8EbkTz1LS0cB4VV0erkCT16ST2KIhHVs0CNdHGGNMjRe2hKGqM/D/LMK3jgJ3BDg2BU9CCbvrxs8DIHXMsKr4OGOMASAjI4OBAwcCsGPHDqKjo0lI8Ey6njdvHrGxsQHPTUlJ4f333+fll1+uklihls30NsaYmqRFixYsWrQIgEcffZRGjRpx7733eo/n5eURE+P/azopKYmkpKSqCNPLFh80xphq5IYbbuCee+5hwIAB3H///cybN48+ffrQq1cv+vTpw+rVqwGYNm0aF154IeBJNjfddBP9+/fnmGOOCVurw1oYxhgDPPb1clZsKznyv2K6Hd2ERy46KeTz1qxZw48//kh0dDRZWVkkJycTExPDjz/+yIMPPsgXX3xR6pxVq1bxyy+/kJ2dzfHHH89tt91WoTkX/ljCMMaYauaPf/wj0dHRAGRmZnL99dezdu1aRITc3Fy/5wwbNoy4uDji4uJo1aoVO3fupH379pUalyUMY4yBcrUEwqVhw4be1//85z8ZMGAAEydOJDU1lf79+/s9Jy4uzvs6OjqavLy8So/LnmEYY0w1lpmZSbt2nmX43n333YjGYgnDGGOqsVGjRvHAAw/Qt29f8vPzIxqLeKZC1A5JSUlang2UEkdPBmwehjF1zcqVKznxxBMjHUaV8Xe/IrJAVV2Nz7UWhjHGGFcsYRhjjHHFEoYxxhhXLGEYY4xxxRKGMcYYVyxhGGOMccUSho+9B45w8asz2LLnYKRDMcbUARkZGfTs2ZOePXvSpk0b2rVr531/5MiRMs+fNm0as2bNqoJIPWxpEB9fL9nGkrRMxiVv4F+XnBzpcIwxtVxZy5uXZdq0aTRq1Ig+ffqEKcLiwrlF63gR2SUiywIcv09EFjk/y0QkX0SaO8dSRWSpcyz0mXjGGFNDLViwgH79+nHaaadx/vnns337dgBefvllunXrRvfu3bnyyitJTU1l7NixvPjii/Ts2ZPp06eHPbZwtjDeBV4F3vd3UFWfA54DEJGLgLtVdY9PlQGqujuM8RljTJFvR8OOpZV7zTanwNAxrqurKnfddRdfffUVCQkJfPrppzz00EOMHz+eMWPGsHHjRuLi4ti3bx9Nmzbl1ltvDblVUhHh3KI1WUQSXVYfAXwcrliMMaYmOHz4MMuWLWPQoEEA5Ofn07ZtWwC6d+/O1VdfzSWXXMIll1wSkfgi/gxDRBoAQ4A7fYoVmCoiCryhquOqIpac3Mgu7GWMiaAQWgLhoqqcdNJJzJ49u9SxyZMnk5yczKRJk/jXv/7F8uXLqzy+6jBK6iJgZonuqL6qeiowFLhDRM4JdLKIjBSRFBFJSU9Pr1AgT01ZVaHzjTGmIuLi4khPT/cmjNzcXJYvX05BQQFbtmxhwIABPPvss+zbt4/9+/fTuHFjsrOzqyy+6pAwrqREd5SqbnP+3AVMBHoHOllVx6lqkqomJSQkhDVQY4wJp6ioKD7//HPuv/9+evToQc+ePZk1axb5+flcc801nHLKKfTq1Yu7776bpk2bctFFFzFx4sRa8dC7TCJyFNAPuManrCEQparZzuvBwOMRCtEYY6rEo48+6n2dnJxc6viMGTNKlR133HEsWbIknGEVE7aEISIfA/2BliKSBjwC1ANQ1bFOtd8DU1X1gM+prYGJIlIY30eq+l244jTGGONOOEdJjXBR5108w299yzYAPcITlTsfzNlkE/eMMaaE6vAMo1rKyy+IdAjGmCpQm3YdDaYy7tMSRgBOl5gxphaLj48nIyOj1icNVSUjI4P4+PgKXSfi8zCMMSZS2rdvT1paGhUdkl8TxMfH0759+wpdwxKGMabOqlevHp07d450GDWGdUkZY4xxxRJGALW9T9MYY0JlCcMYY4wrljCMMca4YgnDGGOMK5YwjDHGuGIJwxhjjCuWMAKwMVLGGFOcJQxjjDGuWMIwxhjjiiUMY4wxrljCMMYY44olDGOMMa6ELWGIyHgR2SUiywIc7y8imSKyyPl52OfYEBFZLSLrRGR0uGIMxpaSMsaY4sLZwngXGFJGnemq2tP5eRxARKKB14ChQDdghIh0C2OcxhhjXAhbwlDVZGBPOU7tDaxT1Q2qegT4BBheqcEZY4wJWaSfYZwlIotF5FsROckpawds8amT5pT5JSIjRSRFRFLqwq5ZxhgTKZFMGAuBTqraA3gF+NIp97eZdsAnCqo6TlWTVDUpISGh8qM0xhgDRDBhqGqWqu53Xk8B6olISzwtig4+VdsD26o6vtP+9QN5+QVV/bHGGFNtRSxhiEgbERHndW8nlgxgPtBVRDqLSCxwJTCpquPLPpzHgSP5Vf2xxhhTbcWE68Ii8jHQH2gpImnAI0A9AFUdC1wG3CYiecAh4Er17IuaJyJ3At8D0cB4VV0erjiNMca4E7aEoaojyjj+KvBqgGNTgCnhiCsU+QU2GcMYYwpFepRUtXbRKzMiHYIxxlQbljCC2LrvUKRDMMaYasMShjHGGFcsYRhjjHHFEoYxxhhXLGEYY4xxxRKGMcYYVyxhGGOMccUSRhkyD+WycfeBSIdhjDERZwmjDBe9MoMB/54W6TCMMSbiLGGUYfOeg5EOwRhjqgVLGLXUruwcvlq0NdJhGGNqkbAtPmgi68Z35rN8Wxb9jkugaYPYSIdjjKkFrIXhaMRB3qr3HK3YG+lQKsX2zBzAVtw1xlQeSxiOS6Jncl70b/wlZkKkQzHGmGrJEoYxxhhXwpYwRGS8iOwSkWUBjl8tIkucn1ki0sPnWKqILBWRRSKSEq4YjTHGuBfOFsa7wJAgxzcC/VS1O/AvYFyJ4wNUtaeqJoUpPmOMMSEI5xatySKSGOT4LJ+3c4D24YrFGGNMxVWXZxg3A9/6vFdgqogsEJGRwU4UkZEikiIiKenp6WEN0hhj6rKIz8MQkQF4EsbZPsV9VXWbiLQCfhCRVaqa7O98VR2H052VlJRkY0iNMSZMItrCEJHuwFvAcFXNKCxX1W3On7uAiUDvyERojDGmUMQShoh0BCYA16rqGp/yhiLSuPA1MBjwO9LKGGNM1Qlbl5SIfAz0B1qKSBrwCFAPQFXHAg8DLYD/ighAnjMiqjUw0SmLAT5S1e/CFacxxhh3wjlKakQZx28BbvFTvgHoUfoMY4wxkVRdRklVGxLpAIwxppqyhOFQSxXGGBOUJQxjjDGuWMIwxhjjiiUMoJPsoCn7Ix2GMcZUaxGf6V0d/Bp3T1iu+9DEpQzv2Y7enZuH5frGGFOVrIURRh/O3czlb8yOdBjGGFMpLGEYY4xxxRKGMcYYVyxhGGOMccUShjHGGFcsYRhjjHHFEkYJQuXswaQa2nW+/G0rn83fUimfXSyOIMeenLyCYx+cUumfaYypnSxhhOilH9eSOHoyefkFrs85dCSf7ZmHgtb526eLGPXFkoqG5+VmZaw3p28kr8A2KTTGuOMqYTibGkU5r48TkYtFpF54Q6ueXv91HQDXvj2Puz7+zdU5142fy1lP/xzOsAK64o3ZvDNzY0Q+2xhTu7htYSQD8SLSDvgJuBF4N1xBVUc/r9pZ7P3sDRl8vXibq3Pnp+4NR0iurE8/wGNfr4jY51cnufkFZOw/HOkwjKmx3CYMUdWDwKXAK6r6e6Bb0BNExovILhHxu72qeLwsIutEZImInOpzbIiIrHaOjXZ7M+E0ZekOv+XXvj2XP3+QUsXRmPL4+2eLOe2JHymwbjhjysV1whCRs4CrgclOWVnrUL0LDAlyfCjQ1fkZCbzufFA08JpzvBswQkSCJqeqNJi5XBf9vff99LW7+X75ziBnmOri6yXuWoTGGP/cJoy/AQ8AE1V1uYgcA/wS7ARVTQb2BKkyHHhfPeYATUWkLdAbWKeqG1T1CPCJU7daeDn6RR6v916Z9QINksrOyWVXVk7A87buO0R2Tm55wzPGmLBxlTBU9VdVvVhVn3Eefu9W1b9U8LPbAb7jSNOcskDlVeoPUcmkxl9FU7IB+HxBGrvL0f8tPsOVsnNyGfj8r/R+6qeA9fuO+ZlhL88I+XOqQk5uPo99vdwSmjF1lNtRUh+JSBMRaQisAFaLyH0V/Gx/Iz81SHmg2EaKSIqIpKSnp1cwpCLXx3i6nTpI0TW//G1r0HNyyxhqe8qjU9mVXXbS2bznoIsIK8/eA0cCHvt68TZ2Oi2iD+du5p2Zqbz6y7qqCq1S+bb6Vu/IZtWOrApd76kpK/lk3uYKRmVMzeG2S6qbqmYBlwBTgI7AtRX87DSgg8/79sC2IOV+qeo4VU1S1aSEhIQKhuS9Ks0lu1TpziBdSbPW76brQ98yPzVYL1z1NOjFZL/lObn53PXxb4wYNweA/AJPQqzMh8YHDuexZmfpv+twEoHz/5PMkP9Mr9B1xiVvYPSEpZUUlTHVn9uEUc+Zd3EJ8JWq5hJ8ErEbk4DrnNFSZwKZqrodmA90FZHOIhILXOnUrTLXRv9Ae9ldqnzexsDJYOY6T/25GzLCFlcoQvmPE6irrfA38m1lTDqsiFveS2Hwi8muZ8Zv3H2Az1IqNiNexM20RmNMSW4TxhtAKtAQSBaRTkDQ9ryIfAzMBo4XkTQRuVlEbhWRW50qU4ANwDrgTeB2AFXNA+4EvgdWAp+p6vKQ7qpClHOi/P/W6PuV1oJMjpGihs/BI/kA/LRqV6nzEtjHXdETqHiOrTqLt+wjJzff77E3p2/k26XbK+VzZoeYYIe9PJ1Rn1fejHhjjHuutmhV1ZeBl32KNonIgDLOGVHGcQXuCHBsCp6EEnHXRv/A76NncNzh91iSlgnxnvIZcX+lvhwhMecjAN6ZmQrAb5v3FTtfFZ6v9zrnRC9lRsEp/KZdPQeyd8DBDGh9UkjxLEnbx8WvzmTSnX3p3r5pBe4ssF1ZOQx/bSaDurUOWOfzBWkMPaVtWD4/mMLEbIypem4feh8lIi8UPlwWkefxtDZqvctjfqWe5BNN8Qfa9SXwg+Ih/0lm0cI5pMZfxQmymQbi6fKJ8r3GC93g9T4hx/PB7E0AXPzqzJDPDebOjxZ6X2cfzgNg2dbMSv0MY0zN5rZLajyQDVzu/GQB74QrqJpu1Y5sFk19H4ALouf4r6RFvykfznP/W/PBAN1EFfXNksBdTCEuvGuMqaXcJowuqvqIM5lug6o+BhwTzsBqiq9i/xFS/Qbk0FGKzwz/alEIM5D9fHnvPXCEM5/6ieXbKqdFUJggCh8NH84roKBAiyWOUHLIrPW7GT/D3QKIn6VsqZEjzYypC9wmjEMicnbhGxHpC4Rv6Ew1tC7+Or/lPaI2hHSdd2OfITnubu97VQ34cNmt6et2syMrh9enrQfKng/ilu9oor0Hi3fB/bxqF0vT3CWoq96cy+PfuFsAcdTnS/jj2Nms3F6xORLGmMrnNmHcCrwmIqkikgq8Cvw5bFHVOMoL9f7LWVHBB3OdELWF3lGri5W98vM6Hv6q8gaBLdi0h64PfcueIJPxAknbezCkVspFrxbNSP9hxU5eq8QJfUNfqtgciao2fW06k1yuXmxMTeV2lNRioIeINHHeZ4nI3wAb3whEoVwaPYPhUTPpcvhDAPL9TG57st74UmWfhrjLnvrpDCqcw/DNku1Bn0WU5exnPMuD/XhPvwCf7d+mjAP86X3Pir13DDi23J8fTE5uPm8mh9aaq0rXvj0PgIt7HB3hSIwJn5B23FPVLGfGN8A9YYinWrsiOuh6i8VkHfKstzQsai5JUWvCFVKYuH9Ckbb3IP2emxaWKAb8u+i6b03fwPM/1LS/R2NqF1ctjADq3HTZZ+q96aqeUMD1MVMB6BIV/Df+smZRz92QwfXvzOPcE1rRO7F5lY5YcjMhevf+0Lu+AGas3U3vzs2D1tm4+4D39aEwjQ4zxrhXkYRRSwdbhp4HxfmriBbPnxdEzaOluHtoGywB5OTmc4WzjtOUpTsCbuJUHt8tC63rKtByGgeP5IX82UvS9nHN23O5oU+it2zLnkN0bNEg5GsVuvd/izn3hFZcEIHJhMbUFUG7pEQkW0Sy/PxkA9ZZ6+jis0RI/6hFNJEDQWq7M2/jHtbt2u+qbrBFEQO59f8WBjwWKIn5K7/qzbkhf3bhA/nkNUUrAV/zdujX8fX5gjRu/zDwPbm1Pn2/N75HvlpGig3xNcYraMJQ1caq2sTPT2NVrUjrpBoLveHUyGeE8buxz/JAzEcVjuLyN2a7rvvUlFUV/jxfhfNC0vYW3ZeqklUJ+2Cc8sj33OesBbXBp8vpwOHgLRWpgh7QEePmMPD5XznvhV8BeG/2Ji4b6/6/A8C6Xfu58JXpZOXkMmPtbtdDj42pCUJ66F0X9IteQjM/S5sHP2dxsfdNpHKmqBQ+OK8si7bs4+dVZW8n62+/i799usg7z8OtZVszueW94vudZx/OI93FniBl8Z27cshnfamt+w4xb+MeRn2+mCN5oc1HKVwIMdQhyb+sLlpw8sUf17Bsaxa/rk7nmrfnFht6HExefgHvzUqttDk0xoRDLW0llF87yaCdhLaC6l9jJpb78wZE/cYvBb38HrvqrYp10/hKHD3Z+zp1zLCQz5++tvRy72X5+2eLWe1yr4uMEL+kb3p3Ph/96Uw2ZxzknOeKRq/1HfOz9/V5J7Zm8EltQrpuIX/Dopek7aNBbAzHtmpUrPzGd+aX6zN8fTRvM49MWk5Obj5/7telwtczJhyshRFh78Q+V+WfmXmwem6xeiiElWhnrc/g/dmprN8d+DnPkfwC1pZzc6YuD5ZeLPniV2d6u6sqauPuA8XWECtsTVZGt58x4WIJow7q8fjUsF173a6iL+it+4p3zZXVHeZvUmIhf4O0ypoh/88vlzHoxWR2ZYc+KKCk9enuBiAUKvAZITD21/Vs9xk+vf9wHgP+PY37/mfzXk3NYgmjBhv9xRJerGaT2c57Idk7amt/iQfZX/4WfOmM3PzKHam912lJZecEfqCenZPLkrR9ZV5rZ2ZR0vHXXVXSXz9Z5H095ttVnPV0UVdZ4Za0hbs0bs88xBcLg+8Xb0x1YAmjBvtk/hZe+mltpMMoJfNQLrPWhf7M44kgCxTmVWAf8cwggwf+/MECLn51ZtkLQPq0cK56M8CS9S6s3ZnNpf+dVazsD/+d5Z2kaEvJm+osrAlDRIaIyGoRWScio/0cv09EFjk/y0QkX0SaO8dSRWSpcyyl9NVNdZW292DIXTgA/1uQVqrss5QtQVeudTPY9tL/zgqYEGat9wxwCNZqGPNt8WHLczfuYXPGQb91J5exltegF5NLlW3LrHiXmTFVIWyjpEQkGngNGASkAfNFZJKqen+NVNXngOec+hcBd6uq70ypAaoa+q+qJqJuetd/fnez1EhJhft3t29WvyIhce//Fgc9HuwX+7G/rqffcQnFyib8Vjq5VYby/B0ZU1XC2cLoDaxzNlw6AnwCDA9SfwTwcRjjMTWY7yTC8phRRheZltEXVBlf5L5Dm42picKZMNoBvmt3pzllpYhIA2AI8IVPsQJTRWSBiIwM9CEiMrJwr/H09PRA1Uw1UNEv/YrYV8ZQ4rKWhQ/HL/4FfpKUPcMw1Vk4E4a/f2OB/jlcBMws0R3VV1VPBYYCd4jIOf5OVNVxqpqkqkkJCQn+qphqYsGmvZV+zUCLIgbjbxmSByYsDelzlm2t+I6Ae6vpfBhjAglnwkgDOvi8bw8EGld5JSW6o1R1m/PnLmAini4uYyrspEe+D/mckmt7/biy7CVW3HC7wGS45BcoBRUYgWbqlnAmjPlAVxHpLCKxeJLCpJKVROQooB/wlU9ZQxFpXPgaGAwsC2OsxkREycmMVf3Qu8uDUxjyUumRW8b4E7ZRUqqaJyJ3At8D0cB4VV0uIrc6x8c6VX8PTFVV3zXBWwMTnW6AGOAjVf0uXLEaEyklf7lfUsbqtpszDtKuWX2ioyovs6zZGdlWjqk5wrr4oKpOAaaUKBtb4v27wLslyjYAPcIZm6kdpq+p2QMdSs7xCLbI46aMA97tcK8/qxOPDT85nKEZU4rN9DY12lszNkY6hEr32fwtfst3ZhUtC//e7E1VFY4xXpYwjKlmRn1hixKa6skShjHV0JSl20strxJscqGqMm/jnjInIBpTEZYwqgHBdlkzxd3+4UIGPu9+743/paRx+Ruz6fzAFFer6Va1KUu3l2tBSlO9WMKoBmIsYZgK2phRNMjQd4vZxNGT+e+00lvuVrXbP1xYqTtImsiwhGFMDRHqEu+FG1g9+91qdu+v+D7qAFv2HOSJb1ZUeLLf4bx8MiopJlN1LGEYU829NX0D2/YdKrUhVSAi8OOKncX2N0964sdS9U55NPCM94/mbiZx9GSyS2wZe/uHC3lrxkZWBFly3o1b3kvhND8xmeotrPMwjDEVMy55PU9NWcUTk1fSslFcsWPPT13NKz+vIy4mioTGxY/5W3597c5sUjbtZUTvjkDwnQjHz/QMV96RmUPj+Hre8tx8T/epvxnp2zMPsXXvIZISm5d5XyXnm6RnH6ZxfAzx9aK9ZT+t3Mns9Rn848JuZV7PVA1rYRhTjT01pWhiX8lupVd+9jybOJxXUGwl4Ge/W8WUpTtKXWvQi8k8MGFpqVZDobS9B/nczyZW/oiftUXP/fevXDZ2tp/aZTv9yR+5fvy8YmU3v5cSkXk2XyxIY/ramj0hNFwsYRhTy3yWEvxL//I3/G8x+8exs7n3f4s5klfgTU57Dhzx+7yiZAtjytLtHCprm9syzN24p+xKVeDv/1vMtW/PK7tiHWQJoxqofoMgTW22cnuW3ySQsd8zukpR7/4hV4ybw72fF+1WWLiHh2/CyMnN5/YPFxZ7Hw6FK+su35ZJpi0NHxH2DMOYOui1X4oPtV23K9u7g82mEvuVT1i4lRcu7wnAdmf/8UWb95FfoJx09FGlNoI64Z/f8fdBx3HXwK6VFu+va9K5fvw8enZoyqIt+4gSzy9av947gI4tGri6xoptWTSMi6ZTi4aVFlddYy0MY+qg539YU+z9jLW7OZLneaA9+MXSy50njp7Mul37vQ/KR09YyrCXZwS9/ss/rfU+JA/kw7nu1sR6+CvP7gaLtuwDPKv8qsLkpcF3SvR1wcvTvYs3Vob8Aq1zM+stYRhjePTrFWXWCXUo7Qs/rGHstPU8OLH4boa+iys+NLH4Nje7snNYuNn9zozqdOiqKg9NXOo6Afm9lipfLw60xxv8snoXiaMns3J7Fjsyc+jy4BQ+CbBQZG1lXVLGmAr5eF7gL82SLZljH5xSagJiss8S9b2f/AmA1DHDvGVb9hws1U1WaLmzVe6UpTv4cO5mAK4+o5O3ZVMvuvTvxMlr0omLieKMY1oUK5++djd3ffxbwHv5YYVns6sFm/bSJaERAF/+ttU7TLkusBZGNaB+tz83pnrZmH7Ab/m/vim7dVLI32z168YHH5H0u2d/CXgs1VkS5ZFJxVsqJ/7zO/r4TFws+XlXjCs9UizzUPEH6Vv2+E9SGuB1XRDWhCEiQ0RktYisE5HRfo73F5FMEVnk/Dzs9lxjTNXyNxmw33OBv8wrYldWjqt6hY8Qdu8/Uqw8r0BJzw5t6ZGSX/4lE9XcDRkA5OYVFD27CJIxpi7fwbZ9hwJXqIHC1iUlItHAa8AgIA2YLyKTVLXkryPTVfXCcp5rjKki/rqFAnUVVVTvp35yVe/gkTxeLNHttdXnS/qKN2bz6Z/PqpSY1jstrMd9WlQaJGOM/GABCY3jmP/QeZXy+dVBOFsYvYF1qrpBVY8AnwDDq+BcY0wdkZpxkJd+WluszHcNrbkb97B4y76w/aZf1iCpUFs5u7JySHriB9buzK5AVOETzoTRDvB9GpbmlJV0logsFpFvReSkEM9FREaKSIqIpKSn23R+Y0xxw1+b6fd5xmcpWygoUEZ/sYQej01lezmSSqjPMPILlCcnr/CbSHbvP8zzU9ewe/8R3pudGvAah/Py2XfwSMDj4RTOhOHvSW7Jv9+FQCdV7QG8AnwZwrmeQtVxqpqkqkkJCQnljdUYU8eM+nwJ81P38Mn8LWQeyuVTP0NkE0dPLtXlFYyq8t6sVM54qvhKvJ/N38LU5TuYvjadN6dv5PQnfyz2UP2rRVtJeuJHPk0pe5juDePn0/PxH1zHVJnCmTDSgA4+79sDxQY5q2qWqu53Xk8B6olISzfn1iY2SsqYyFi+rWhuyYbd/keBvfTT2oALNqoqr/68lndnbmTmut10fmAKj0xazs6sohbEzqwcRn2xhJEfLCg2K/53z/5C5qFcFm/Zx18/WVTsul8t2uYdxvv14m08Omm599hs5+F7JEi4ZiqKSAywBhgIbAXmA1ep6nKfOm2AnaqqItIb+BzoBESXda4/SUlJmpKSEnqwjx4V+jmV6Jic/6PARjgbU+MULlVSXjef3Zm3g6zImzpmGImjJ3tf/7RyJze/5/mOe+u6JI5JaMgxzpyQ8hKRBaqa5KZu2EZJqWqeiNwJfI8nAYxX1eUicqtzfCxwGXCbiOQBh4Ar1ZPB/J4brliNMaY8KpIsgKDJoqQFm/Z6kwXALe97XvtOcgy3sM70drqZppQoG+vz+lXgVbfnGmNMXfWH12f5Lb/6rTl8cNMZREWFv2vb+kGMMaaaOuvpsuejzFyXwdnP+J/VXtksYVQDdW15AWOMO4XLyZdlm8t6FWUJwxhjjCuWMIwxxrhiCcMYY4wrljCMMca4YgnDGGOMK5YwqgFbGsQYUxNYwjDGGOOKJQxjjDGuWMIwxhjjiiUMY4wxrljCMMYY44oljGrBRkkZY6o/SxjGGGNcsYRhjDHGlbAmDBEZIiKrRWSdiIz2c/xqEVni/MwSkR4+x1JFZKmILBKRcuy7aowxpjKFbcc9EYkGXgMGAWnAfBGZpKorfKptBPqp6l4RGQqMA87wOT5AVXeHK0ZjjDHuhbOF0RtYp6obVPUI8Akw3LeCqs5S1b3O2zlA+zDGY4wxpgLCmTDaAVt83qc5ZYHcDHzr816BqSKyQERGhiE+Y4wxIQhblxT+x4r63Y1URAbgSRhn+xT3VdVtItIK+EFEVqlqsp9zRwIjATp27FjxqI0xxvgVzhZGGtDB5317YFvJSiLSHXgLGK6qGYXlqrrN+XMXMBFPF1cpqjpOVZNUNSkhIaESwzfGGOMrnAljPtBVRDqLSCxwJTDJt4KIdAQmANeq6hqf8oYi0rjwNTAYWBbGWI0xxpQhbF1SqponIncC3wPRwHhVXS4itzrHxwIPAy2A/4oIQJ6qJgGtgYlOWQzwkap+F65YjTHGlC2czzBQ1SnAlBJlY31e3wLc4ue8DUCPkuXGGGMix2Z6G1ONnNCmcaRDMCYgSxjGGGNcsYRhTDU37d7+3Ng3MdJhGGMJw5jqZvHDg72vU8cMI7FlQx656CQ6Nm9Q7mt+c9fZZdYZ0btDmXVM3WYJw5hqREQ4qkG9AMeCn/vwhd24tFc7RvQuPYH15HZHMX3UgKDnd0lo5DpOUzdZwjCmhmgU5xnU+NjFJzHngYEkdWpW7PhNZ3fmhSt6FkssXVs14nddWwLQoXkDYqI8B7skNCx1ffW7DoMxRSxhGFMN3dAnkXduPL1YWWEi6NWxKW2Oiufz2/p4j7U9Kt77+tJeniXbXh7Rix/u6ccHNxctAP3U70+hecNYYqJK/9NXPyv3LH10MENPbuN9HxttXxl1WVjnYRhjyufRi08qVSZ+lmf77Z+DaBAXTT2fBJCU2JzUMcP8Xvfy0ztw+ekdWLY1k2e+W8X0tZ7dA1o2ivXWiY2JYsJtfWjXtD6N4+vRu3Nzvl22A4B3bzqdq96cW+q6HZs3YPOeg2Xe16kdm7Jw874y65nqyRKGMTXE05eewjPfreJ4n7kazRrGBjkjsJPbHcUHN5/B7v2HSXriR1RhyElteWrKKibd2ZcT2jTx1i1MU9ed1Yk+XVr6vV7yqAEcySvguH98W6x849MXALB6ZzYJjeKYs2EPCz9aWK6YTeRZ+9KYaiTYc+3CL/m4mOhK/zwFOrZoQOqYYcWSBXgexPt654biXWWFYmOiSL5vAE3iPb+H/ueKnogIIsIJbZrQolFcqW6vo+r7f8Dvzx9Ote1yIs0ShjHVSKSeO2uQJ97d2x8F4G1dDDihFQAXnOJ5tnH1GUWjsjq2aEDKPwax4vHzuaRX6e1vSj4DuebM0iO6LupxtPd1q8Zx3tdNA4weO7ZV8dFdn4w8k+gosbkrYWBdUsZUI8G+uMOhQaznK2BwtzYB6/Tq2Iyljw6mcXzRF/aaJ4YSEyVEXV26TRQbE0VsgN9FzzuxNaOHnsCYb1cBcMeAY1GFeRv3kLLJs/nmKyN68cqIXgDsP5zH+7NTOXQkn1v7daFrq0aMnrCU+84/nue+Xw3AV3f0JSZaiIuJRlUREdY/5ekKe2dmaqkYnr2sO93aNuHCV2Zw3VmdeH/2prL+mkppEBvN83/swW0f1q3uNWthGFONdGvbpOxKlah+bDTzHhrIE78/OWg932QBnqQQFVXGxBA/oqKEW/t18b5vEBvDqCEn8N+rT/Vbv1FcDLf3P5a/Dz6ehnExXHF6BxY/Mpg7BhxLY2eYcb3oKG83XcnuM4BzjkvgXKdV1KF5fS5P6sDJ7Y4idcwwHh9+crEH/oUCDRootOLxIcXe/3pff1Y+PoRHLupWqu5Xd/QNeq2axFoYxlQjp5aYW1EVWjWOL7tSuGNoEs/6py4gvyB4C0tEvM89pt3XnyVbM4mNCfx775onhhIdJUQHSW4/3N2P9P2H6dCsASc+XLSLwl8GdqVNk3hOT2xGXEw0j0xaxi+r070LRPpG2qmFZ17LjX07s+9gLt2ObsL2fYc4s0sLjuQVAJ4k+9AFJ3L+SW048+mfSsUx78GB9H7KU/7bPweRW1BA7ydL1wP40+868+b0jQHvKVwsYVQDLRvFsXv/Yb/HHrrgRJ6csrKKIyoSXy+KnNyCiH1+XVM4ya4uKuuLvaQWjeIYcHyroHWCJZNCzRrGekebzXtoIBvSDwBwz6DjitV758bim34m+Dxf8XV3ifNWbMsCoFeHplzfJ9HvOacnNqNVk3jmPTSQ5VuzvPH8Y9iJPDG59L//y07rEJGEYV1SEdYrZyy/3tefP59zDMseO5+rzuhI/Xqe5nXTBvWq7MHdnQOOLVUWFxNFmyae3z7LWovox3vOCUtcdU3hb6q13atX9eLZy7pHOoxSWjWO58xjWriqe3pic849oRXtm9UPWu/Eto25f8gJ3ucyAIseHsRrV51K6yZxTB81gPdvOsP7+YWDCkpa9PAgUscMI3XMMI5v05gLu7flzGOau7yzymEJI0z+euR2Ugtae9+n/u55dlz2NTya6S37us1d3DHsDBrGxfDABSfSKC6Gp35/CjNHnwt4hjzGREex7smhQT/ruNahrwH00pU9vZ8D0Ltz6clelyd14OKenpEuHZqVXvjOt36Lhv5/2yqPl67sGfT4DX0S+cu5x1K/XjQvXN6D+84/vtI+21SNC7sfzeVJNX+xw/E3nM6M+88NWkdEuK1/F1o1Ker6a9oglmHd2zL3wfPo0LwB9WP9D5Xu1bEpAOOuPY2mDYo/a3n1qlP5ZORZJHVqxmWnVc2Q47B2SYnIEOAlPFu0vqWqY0ocF+f4BcBB4AZVXejm3Grpqv9BVhpT4wZx1iHl/Am9OV62MOnpv5DoU22gjOP63kdz3dDfubpsjJ/lGJ6+9BQemLCUo+rX46Fh3bh+/DwA+nRpwaz1GWVec7iTCAZ1a80PK3Z61xjy1bNDU37fqx239juGBrExxMVEcUOfRN5I3uAq7vIa3rMdz09dw+Y9B3n2su6M+nyJ99gPd59D19aePuR7BhclisIRM6GIEvDXZd44PobsnLzQAzemkp3WqTlLHh1Mk/jA81V8l4gJt7AlDBGJBl4DBgFpwHwRmaSqK3yqDQW6Oj9nAK8DZ7g8t/o5zrMsdeHi1KMnLGWJdilV7adHrgj50s9e1p1t+w4RJcKcDRmM6N2Rrq0a0aF5AzIP5XrrFfYBP3pRN/5wWnsaxsbwRvIG2jerz0U9jiZx9ORi1x1z6Sl0a9ukVDN8+qgBdHCW0y4cern6CU9Lp32z+t7+22n39ue75Tto1jCWt69PolOLBpz3QjLgaSlMWLiVYae05cS2Tbj/iyWs2J7FE5eczD++XOb9rITGcRzOzSfL50u6MH/Viy6eyEqOuS8pqVMzGsbF8OuadADuHXwc/566BoDmDWPZc+AIC/5xHml7D3FC28Yc/4/viIuJ4ud7+9N3zM8ALPznIApUvSNvdmXlkJWTx+od2fTs2JRXflrLJ/O3eD9z2Cltmbx0e7E4Bp7Qip9W7SpWFhMlrHliKK/9so7nf1hTKvY3rj0t6L2ZuilYsqhq4Wxh9AbWOftzIyKfAMMB3y/94cD76hl8PkdEmopIWyDRxbnVXnn79ZvWr8fFPY4u9oDMt/n+l4FdAc+aQQCtm8Rzy9mdGdStNUvSMpm+djfnHJfgHQp5W/+ipDXx9j7Fhki2aBRX6iEd4E0W/lx7VlFciS0beodJDjzR0wWXfN8A0vcf5rROzbwtGYCPR57JtNW7GN6zHevT93vHyE+7tz8N42KKJbPLT+/As9+tpt9xrRjWvS2Tl3i+kFX9L/M9fdQAVu/I5rxurTmcl092Th4tG3mSWmHCaNU4jj0HjhAdJfTo0BQo3q32/B97cGyrRtQr0aJr1SSeVk2KktWYP3Rn675D3nWYXrv6VJ45nMfJj3wPeEa7tGoSz5wNGWTn5PGn91MAqF8vmqgo4a6BXWnZOI4HJiwFPIn1d10TaF7OZT6MqSoSrolCInIZMERVb3HeXwucoap3+tT5BhijqjOc9z8B9+NJGEHP9bnGSGAkQMeOHU/btCn0STgc2gvPJIZ+nq+hz8EZIyt2jUqgqqTvP1zuoZJZObmohrZkQ3nk5Rew58CRYv268zbuYVPGAf6Y1AFVJb9Avd1xa3dmM211On8655iQP2vK0u3Uj42mW9smzFi7mz9UUn9v8pp0Mg/lemcmf5ayhc4tG3J6YvEHkd8s2can87fwyEXdOLZV0TpQmzMOMmnxVu4YcKzf+QPGVAURWaCqSa7qhjFh/BE4v8SXfm9VvcunzmTg6RIJYxRwTFnn+pOUlKQpKSlhuR9jjKmNQkkY4eySSgN8h0G0B7a5rBPr4lxjjDFVKJzDaucDXUWks4jEAlcCk0rUmQRcJx5nApmqut3lucYYY6pQ2FoYqponIncC3+MZGjteVZeLyK3O8bHAFDxDatfhGVZ7Y7BzwxWrMcaYsoXtGUYk2DMMY4wJTSjPMGymtzHGGFcsYRhjjHHFEoYxxhhXLGEYY4xxpVY99BaRdKAcU70BaAnsrsRwagK759qvrt0v2D2HqpOqJripWKsSRkWISIrbkQK1hd1z7VfX7hfsnsPJuqSMMca4YgnDGGOMK5YwioyLdAARYPdc+9W1+wW757CxZxjGGGNcsRaGMcYYVyxhGGOMcaXOJwwRGSIiq0VknYiMjnQ8oRCRDiLyi4isFJHlIvJXp7y5iPwgImudP5v5nPOAc6+rReR8n/LTRGSpc+xlcbaAE5E4EfnUKZ8rIolVfqN+iEi0iPzm7NpY6+/Z2b74cxFZ5fz3PqsO3PPdzv/Xy0TkYxGJr233LCLjRWSXiCzzKauSexSR653PWCsi17sKWFXr7A+epdPX49nhLxZYDHSLdFwhxN8WONV53RhYA3QDngVGO+WjgWec192ce4wDOjv3Hu0cmwecBQjwLTDUKb8dGOu8vhL4NNL37cRyD/AR8I3zvlbfM/AecIvzOhZoWpvvGWgHbATqO+8/A26obfcMnAOcCizzKQv7PQLNgQ3On82c183KjDfS/xAi/D/lWcD3Pu8fAB6IdFwVuJ+vgEHAaqCtU9YWWO3v/vDsN3KWU2eVT/kI4A3fOs7rGDyzSSXC99ke+Ak4l6KEUWvvGWiC58tTSpTX5ntuB2xxvtBigG+AwbXxnoFEiieMsN+jbx3n2BvAiLJiretdUoX/UxZKc8pqHKep2QuYC7RWz86FOH+2cqoFut92zuuS5cXOUdU8IBNoEZabcO8/ePZ+L/Apq833fAyQDrzjdMO9JSINqcX3rKpbgX8Dm4HteHbjnEotvmcfVXGP5fruq+sJQ/yU1bhxxiLSCPgC+JuqZgWr6qdMg5QHOyciRORCYJeqLnB7ip+yGnXPeH4zPBV4XVV7AQfwdFUEUuPv2em3H46n6+VooKGIXBPsFD9lNeqeXajMeyzXvdf1hJEGdPB53x7YFqFYykVE6uFJFh+q6gSneKeItHWOtwV2OeWB7jfNeV2yvNg5IhIDHAXsqfw7ca0vcLGIpAKfAOeKyP9Ru+85DUhT1bnO+8/xJJDafM/nARtVNV1Vc4EJQB9q9z0Xqop7LNd3X11PGPOBriLSWURi8TwUmhThmFxzRkK8DaxU1Rd8Dk0CCkc9XI/n2UZh+ZXOyInOQFdgntPszRaRM51rXlfinMJrXQb8rE6nZySo6gOq2l5VE/H89/pZVa+hdt/zDmCLiBzvFA0EVlCL7xlPV9SZItLAiXUgsJLafc+FquIevwcGi0gzpzU32CkLrqof8FS3H+ACPKOL1gMPRTqeEGM/G08zcgmwyPm5AE8f5U/AWufP5j7nPOTc62qckRROeRKwzDn2KkWrAMQD/wPW4RmJcUyk79sn5v4UPfSu1fcM9ARSnP/WX+IZ2VLb7/kxYJUT7wd4RgfVqnsGPsbzjCYXz2/9N1fVPQI3OeXrgBvdxGtLgxhjjHGlrndJGWOMcckShjHGGFcsYRhjjHHFEoYxxhhXLGEYY4xxxRKGMX6IyH7nz0QRuaqSr/1gifezKvP6xoSLJQxjgksEQkoYIhJdRpViCUNV+4QYkzERYQnDmODGAL8TkUXO/gzRIvKciMwXkSUi8mcAEekvnr1JPgKWOmVfisgC8ezpMNIpGwPUd673oVNW2JoR59rLnL0NrvC59jQp2g/jw8L9DoypSjGRDsCYam40cK+qXgjgfPFnqurpIhIHzBSRqU7d3sDJqrrReX+Tqu4RkfrAfBH5QlVHi8idqtrTz2ddimdGdw+gpXNOsnOsF3ASnvV+ZuJZU2tGZd+sMcFYC8OY0AwGrhORRXiWkm+BZ00f8Kzrs9Gn7l9EZDEwB89Cb10J7mzgY1XNV9WdwK/A6T7XTlPVAjxLwCRWwr0YExJrYRgTGgHuUtViC7WJSH88y477vj8Pz+Y1B0VkGp51fcq6diCHfV7nY/92TQRYC8OY4LLxbH9b6HvgNmdZeUTkOGczo5KOAvY6yeIE4EyfY7mF55eQDFzhPCdJwLN957xKuQtjKoH9lmJMcEuAPKdr6V3gJTzdQQudB8/pwCV+zvsOuFVEluBZWXSOz7FxwBIRWaiqV/uUT8Sz5eZiPKsQj1LVHU7CMSbibLVaY4wxrliXlDHGGFcsYRhjjHHFEoYxxhhXLGEYY4xxxRKGMcYYVyxhGGOMccUShjHGGFf+H70bJUEK+UtSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "itr_result.plot_loss_train_valid_curves(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ca1b7-f91f-4fc1-a047-824c2c548f98",
   "metadata": {},
   "source": [
    "# Stability Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05904081-bc5e-4707-8822-de6e16cc01a5",
   "metadata": {},
   "source": [
    "First, let's do the training a bit more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f94b15-f5fd-49e5-ac1b-2cf64950f190",
   "metadata": {},
   "source": [
    "We'll preproces the images into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a363b10-0342-4357-8d13-e0f5bced6b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_imgs(src_dir):\n",
    "    location = os.path.join(os.path.abspath(\"\"), \"ti200-preprocess\")\n",
    "    try:\n",
    "        os.mkdir(location)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(os.path.join(location, \"train\"))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(os.path.join(location, \"val\"))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    class_names = os.listdir(os.path.join(src_dir, \"train\"))\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        print(class_name)\n",
    "        # Deal with training and validation images separately\n",
    "        old_class_path_train = os.path.join(src_dir, \"train\", class_name, \"images\")\n",
    "        old_class_path_val = os.path.join(src_dir, \"val\", class_name)\n",
    "        \n",
    "        this_class_loc_train = os.path.join(location, \"train\", class_name)\n",
    "        try:\n",
    "            os.mkdir(this_class_loc_train)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        this_class_loc_val = os.path.join(location, \"val\", class_name)\n",
    "        try:\n",
    "            os.mkdir(this_class_loc_val)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        # Iterate through training images\n",
    "        for img_name in os.listdir(old_class_path_train):\n",
    "            this_path = os.path.join(old_class_path_train, img_name)\n",
    "            new_path = os.path.join(\n",
    "                this_class_loc_train,\n",
    "                img_name.split(\".\")[0] + \".pt\"\n",
    "            )\n",
    "            img_tensor = inception_transform(\n",
    "                Image.open(this_path).convert(\"RGB\")\n",
    "            )\n",
    "            torch.save(img_tensor, new_path)\n",
    "            \n",
    "        # Iterate through val images\n",
    "        for img_name in os.listdir(old_class_path_val):\n",
    "            this_path = os.path.join(old_class_path_val, img_name)\n",
    "            new_path = os.path.join(\n",
    "                this_class_loc_val,\n",
    "                img_name.split(\".\")[0] + \".pt\"\n",
    "            )\n",
    "            img_tensor = inception_transform(\n",
    "                Image.open(this_path).convert(\"RGB\")\n",
    "            )\n",
    "            torch.save(img_tensor, new_path)\n",
    "    \n",
    "#preprocess_imgs(\"Project/tiny-imagenet-200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b965c-9ce9-4aac-990e-4707967d4a22",
   "metadata": {},
   "source": [
    "We need a new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ee6902c-87b1-4f3f-bfcf-e2280deb76f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BetterTripletRankingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 img_dir : str,\n",
    "                 pos_per_img : int,\n",
    "                 neg_per_pos : int,\n",
    "                 transform=None,\n",
    "                 training=True\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Point at directory which has subdirectories corresponding to\n",
    "        each class. Supply the number of positive images per image in\n",
    "        the subdirectories and the number of negative images to combine\n",
    "        with.\n",
    "        \"\"\"\n",
    "        if transform is None:\n",
    "            transform = nn.Identity()\n",
    "        self.transform = transform\n",
    "        self.mode = \"RGB\"#ImageReadMode.RGB\n",
    "        \n",
    "        #\n",
    "        # Initialize triplets\n",
    "        #\n",
    "        self.triplets = [ ]\n",
    "        \n",
    "        if training:\n",
    "            self._train_init(img_dir, pos_per_img, neg_per_pos)\n",
    "        else:\n",
    "            self._val_init(img_dir, pos_per_img, neg_per_pos)\n",
    "        \n",
    "    def _train_init(self, img_dir, pos_per_img, neg_per_pos):\n",
    "        # Generate randoms first, index into later. Need to count\n",
    "        # Iterate over classes\n",
    "        class_names = os.listdir(img_dir)\n",
    "        if os.path.exists(os.path.join(img_dir, class_names[0], \"images\")):\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x, \"images\"),\n",
    "                class_names\n",
    "            ))\n",
    "        else:\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x),\n",
    "                class_names\n",
    "            ))\n",
    "        for subdir_path in subdirectories_paths:\n",
    "            img_per_class = len(os.listdir(subdir_path))\n",
    "            break\n",
    "        randoms = np.random.randint(\n",
    "            0,\n",
    "            img_per_class,\n",
    "            (\n",
    "                len(subdirectories_paths),\n",
    "                img_per_class,\n",
    "                pos_per_img,\n",
    "                neg_per_pos + 1 # Last for positive selection\n",
    "            ),\n",
    "            dtype=\"int16\"\n",
    "        )\n",
    "        \n",
    "        # TODO - this method inefficient, only need to hold 2 numbers,\n",
    "        # some string format info\n",
    "        # DANGER - potential for loops with symbolic/hard links\n",
    "        # Iterate over classes\n",
    "        for subdir_idx, subdir_path in enumerate(subdirectories_paths):\n",
    "            exclude_subdir_idx =  [\n",
    "                            *range(subdir_idx),\n",
    "                            *range(\n",
    "                                subdir_idx + 1,\n",
    "                                len(subdirectories_paths)\n",
    "                            )\n",
    "                        ]\n",
    "            # Iterate over images\n",
    "            for img_idx, img in enumerate(os.listdir(subdir_path)):\n",
    "                img_path = os.path.join(subdir_path, img)\n",
    "                # Iterate over alike images\n",
    "                for pos_it in range(pos_per_img):\n",
    "                    pos_rand = randoms[subdir_idx][img_idx][pos_it][-1]\n",
    "                    # Adjust on equal\n",
    "                    if pos_rand == pos_it:\n",
    "                        if pos_rand == 0:\n",
    "                            pos_rand += 1\n",
    "                        else:\n",
    "                            pos_rand -= 1\n",
    "                    # Form name\n",
    "                    pos_path = os.path.join(\n",
    "                        subdir_path,\n",
    "                        f\"{class_names[subdir_idx]}_{pos_rand}.pt\"\n",
    "                    )\n",
    "                    # Need more randoms for next step\n",
    "                    neg_class_rands = np.random.choice(\n",
    "                        exclude_subdir_idx,\n",
    "                        neg_per_pos,\n",
    "                        replace=True\n",
    "                    )\n",
    "                    # Iterate over dissimilar images\n",
    "                    for neg_it in range(neg_per_pos):\n",
    "                        class_rand = neg_class_rands[neg_it]\n",
    "                        neg_class_path = subdirectories_paths[class_rand]\n",
    "                        neg_class = class_names[class_rand]\n",
    "                        neg_rand = randoms[subdir_idx][img_idx][pos_it][neg_it]\n",
    "                        # Form name\n",
    "                        neg_path = os.path.join(\n",
    "                            neg_class_path,\n",
    "                            f\"{neg_class}_{neg_rand}.pt\"\n",
    "                        )\n",
    "                        # Append\n",
    "                        self.triplets.append((img_path, pos_path, neg_path))\n",
    "                        \n",
    "    def _val_init(self, img_dir, pos_per_img, neg_per_pos):\n",
    "        # Generate randoms first, index into later. Need to count\n",
    "        # Iterate over classes\n",
    "        class_names = os.listdir(img_dir)\n",
    "        \n",
    "        if os.path.exists(os.path.join(img_dir, class_names[0], \"images\")):\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x, \"images\"),\n",
    "                class_names\n",
    "            ))\n",
    "        else:\n",
    "            subdirectories_paths = list(map(\n",
    "                lambda x : os.path.join(img_dir, x),\n",
    "                class_names\n",
    "            ))\n",
    "            \n",
    "        img_per_class = dict()\n",
    "        img_names = []\n",
    "        for idx in range(len(class_names)):\n",
    "            subdir_path = subdirectories_paths[idx]\n",
    "            class_name = class_names[idx]\n",
    "            img_names.append(list(os.listdir(subdir_path)))\n",
    "            img_per_class[class_name] = len(img_names[-1])\n",
    "        \n",
    "        # TODO - this method inefficient, only need to hold 2 numbers,\n",
    "        # some string format info\n",
    "        # DANGER - potential for loops with symbolic/hard links\n",
    "        # Iterate over classes\n",
    "        for subdir_idx, subdir_path in enumerate(subdirectories_paths):\n",
    "            exclude_subdir_idx =  [\n",
    "                            *range(subdir_idx),\n",
    "                            *range(\n",
    "                                subdir_idx + 1,\n",
    "                                len(subdirectories_paths)\n",
    "                            )\n",
    "                        ]\n",
    "            this_dir = img_names[subdir_idx]\n",
    "            # Iterate over images\n",
    "            for img_idx, img in enumerate(this_dir):\n",
    "                img_path = os.path.join(subdir_path, img)\n",
    "                # Iterate over alike images\n",
    "                for pos_it in range(pos_per_img):\n",
    "                    # Form name\n",
    "                    rand_idx = np.random.choice([\n",
    "                        *range(pos_it),\n",
    "                        *range(pos_it + 1, img_per_class[class_names[pos_it]])\n",
    "                    ])\n",
    "                    pos_name = this_dir[rand_idx]\n",
    "                    # Form path\n",
    "                    pos_path = os.path.join(subdir_path, pos_name)\n",
    "                    # Need more randoms for next step\n",
    "                    neg_class_rands = np.random.choice(\n",
    "                        exclude_subdir_idx,\n",
    "                        neg_per_pos,\n",
    "                        replace=True\n",
    "                    )\n",
    "                    # Iterate over dissimilar images\n",
    "                    for neg_it in range(neg_per_pos):\n",
    "                        class_rand = neg_class_rands[neg_it]\n",
    "                        neg_class_path = subdirectories_paths[class_rand]\n",
    "                        neg_class = class_names[class_rand]\n",
    "                        # Select from the directory\n",
    "                        neg_name = np.random.choice(img_names[class_rand])\n",
    "                        # Form name\n",
    "                        neg_path = os.path.join(neg_class_path, neg_name)\n",
    "                        # Append\n",
    "                        self.triplets.append((img_path, pos_path, neg_path))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    \n",
    "    @lru_cache(maxsize=256)\n",
    "    def __getitem__(self, idx):\n",
    "        this_triplet = self.triplets[idx]\n",
    "        #query = self.transform(read_image(this_triplet[0], self.mode))\n",
    "        #positive = self.transform(read_image(this_triplet[1], self.mode))\n",
    "        #negative = self.transform(read_image(this_triplet[2], self.mode))\n",
    "        query = self.transform(this_triplet[0])\n",
    "        positive = self.transform(this_triplet[1])\n",
    "        negative = self.transform(this_triplet[2])\n",
    "        return query, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5f35c13-1c04-4b0a-a351-6eb212d75ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82aea099-18e2-45fe-8ad5-1e864b9383a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Documents\\Winter2022\\CIS472\\Project\\ti200-preprocess\\train C:\\Users\\Gabriel\\Documents\\Winter2022\\CIS472\\Project\\ti200-preprocess\\train\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(os.path.abspath(\"\"), \"Project\", \"ti200-preprocess\", \"train\")\n",
    "val_path = os.path.join(os.path.abspath(\"\"), \"Project\", \"ti200-preprocess\", \"train\")\n",
    "print(train_path, val_path)\n",
    "trd_val = BetterTripletRankingDataset(\n",
    "    val_path,\n",
    "    1,\n",
    "    1,\n",
    "    transform=(lambda x : torch.load(x)),\n",
    "    training=False\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "tr_val_loader = torch.utils.data.DataLoader(trd_val, batch_size=batch_size,\n",
    "                                     num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c958b0-086d-4bdb-83ec-edff5879ddd3",
   "metadata": {},
   "source": [
    "Prepare new model that maps into a 64 dimensional encoding space. Note that this is less than the 200 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f8122d-8277-47e8-be6a-9cc7e51d5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_inception_encoder = torchvision.models.inception_v3(\n",
    "    pretrained=True,\n",
    "    aux_logits=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "771a4bb3-2982-49a8-be43-210099ca66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set them all to frozen by default\n",
    "for param in stability_inception_encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d0b3dcf-2c08-44ab-a88c-8442edbf0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's thaw some layers\n",
    "for param in stability_inception_encoder.Mixed_7c.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23d748dc-c37c-47b9-9fa1-d77c7d7b4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_inception_encoder.fc = nn.Linear(2048, 64) # 64-Dimensional Encoding\n",
    "\n",
    "stability_inception_triplet_ranking = TripletRanker(\n",
    "    stability_inception_encoder\n",
    ").to(device)\n",
    "\n",
    "stability_inception_triplet_ranking = StabilityTrainingModel(\n",
    "    stability_inception_triplet_ranking\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70389e-a546-4977-86b0-4015489004e5",
   "metadata": {},
   "source": [
    "Training controllers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d281a669-35db-47f2-8ad9-826069292d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitr_optimizer = optim.Adam(\n",
    "    stability_inception_triplet_ranking.parameters(),\n",
    "    lr=0.005,\n",
    "    betas=(0.8,0.99)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78846344-1e11-4d70-969b-48bd3072f714",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13f3a021-4354-44c2-9caf-7c14d7f65c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitr_result = TrainResult(stability_inception_triplet_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad710510-a550-4213-b468-009706b21a6b",
   "metadata": {},
   "source": [
    "Triplet loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab1332be-6af6-480a-9814-9fb72b198dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.01\n",
    "\n",
    "triplet_loss = nn.TripletMarginLoss(1.0, 2)\n",
    "triplet_stability_loss = T.Lambda(\n",
    "    lambda x : \\\n",
    "        (x[0][0] - x[1][0]).norm() + (x[0][1] - x[1][1]).norm() + (x[0][2] - x[1][2]).norm()\n",
    ")\n",
    "\n",
    "def sitr_loss(clean_output, distort_output):\n",
    "    \"\"\"Note that this will apply softmax to distort_output.\"\"\"\n",
    "    return (\n",
    "        triplet_loss(*clean_output)\n",
    "        + ALPHA * triplet_stability_loss((clean_output, distort_output))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ef9b4-1872-415e-a831-8e22efc769fc",
   "metadata": {},
   "source": [
    "Training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f6014ff-e0bd-496b-8c13-7799fa6f10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitr_best_loss = float(\"inf\")\n",
    "sitr_best_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58993583-da2e-4acb-a549-747fbea800e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e30efafd744962b61cc7a233c56c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "...done.\n",
      "Current Learning Rate: 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f4c1c1077d43b5b85519024c5e8a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Iteration:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train for some number of epochs\n",
    "SITR_EPOCH_COUNT = 8\n",
    "SITR_SAVE_PERIOD = 1\n",
    "\n",
    "loss = torch.Tensor([0])\n",
    "for epoch in tqdm_variant(\n",
    "    range(SITR_EPOCH_COUNT),\n",
    "    desc=f\"Epoch\",\n",
    "    unit=\"epoch\",\n",
    "    disable=False\n",
    "):\n",
    "    # For this training loop, we'll switch up the data each time.\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        del trd, tr_train_loader\n",
    "    except NameError:\n",
    "        pass\n",
    "    trd = BetterTripletRankingDataset(\n",
    "        train_path,\n",
    "        1,\n",
    "        1,\n",
    "        transform=(lambda x : torch.load(x))\n",
    "    )\n",
    "    tr_train_loader = torch.utils.data.DataLoader(\n",
    "        trd,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=True\n",
    "    )\n",
    "    print(\"...done.\")\n",
    "    \n",
    "    # Debug learning rate\n",
    "    print(f\"Current Learning Rate: {sitr_optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "    train_loss = triplet_epoch(\n",
    "        stability_inception_triplet_ranking,\n",
    "        tr_train_loader,\n",
    "        sitr_optimizer,\n",
    "        device,\n",
    "        sitr_loss,\n",
    "        sitr_result\n",
    "    )\n",
    "\n",
    "    val_loss = triplet_epoch(\n",
    "        stability_inception_triplet_ranking,\n",
    "        tr_val_loader,\n",
    "        sitr_optimizer,\n",
    "        device,\n",
    "        sitr_loss,\n",
    "        sitr_result,\n",
    "        training=False\n",
    "    )\n",
    "    \n",
    "    # Save a copy for safety\n",
    "    if val_loss < sitr_best_loss:\n",
    "        torch.save(\n",
    "            stability_inception_triplet_ranking, \n",
    "            os.path.join(\n",
    "                os.path.abspath(\"\"),\n",
    "                f\"best_sitr_{sitr_best_count}_{int(time.time()) % 1000000:06}.pt\"\n",
    "            )\n",
    "        )\n",
    "        sitr_best_count += 1\n",
    "        sitr_best_loss = val_loss\n",
    "        \n",
    "    if epoch % SITR_SAVE_PERIOD == SITR_SAVE_PERIOD - 1:\n",
    "        torch.save(\n",
    "            inception_triplet_ranking,\n",
    "            os.path.join(\n",
    "                os.path.abspath(\"\"),\n",
    "                f\"sitr_{epoch}_{int(time.time()) % 1000000:06}.pt\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Print the last loss calculated and the epoch\n",
    "    print(f\"\\nEpoch {epoch}: Training Loss: {train_loss}, \" \\\n",
    "          f\"Validation Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb10b8-24c6-4ca9-bd0f-cfe1fc8993c2",
   "metadata": {},
   "source": [
    "Let's double check gradient calculations went well:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0ddc6-71f3-48b9-99a8-609959b4d063",
   "metadata": {},
   "source": [
    "The old way of saving is taking up lots of memory, let's just save the part that changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee350bee-4778-4cc4-9770-b149f03a8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    inception_triplet_ranking.model.state_dict(),\n",
    "    \"inception_triplet_ranking_2.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dc76c16-689c-4fab-b928-1c4753cff369",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_result.save(_def_save_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9505d0-ffdd-4b13-a466-d7afbdc07649",
   "metadata": {},
   "source": [
    "Let's also take a look at training/testing curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9099fa9c-d69b-4bd9-89ad-62a0f31e9287",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "itr_result.plot_loss_train_valid_curves(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb6819-cb77-45ab-9c77-4ed81811e757",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Feature Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cac5da-f130-4a72-b4f1-690c88449874",
   "metadata": {},
   "source": [
    "First, run the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "650b0ea3-f7dd-4782-98a7-3d614e8a6e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd16aa26e24d44e7925de1c431eb2cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_observations, stabilized_observations = make_observations(\n",
    "    inception_triplet_ranking.model.to(\"cpu\"),\n",
    "    None,\n",
    "    os.path.join(os.path.abspath(\"\"), \"tiny-imagenet-200\", \"test\", \"images\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5fc15a-a1fb-4cc5-bde0-c9b1b9fafaf3",
   "metadata": {},
   "source": [
    "Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb3a8a68-902d-464d-8b2a-4cdd322fc37b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp/ipykernel_1128/2350893480.py:32: MatplotlibDeprecationWarning: Passing the fontdict parameter of _set_ticklabels() positionally is deprecated since Matplotlib 3.3; the parameter will become keyword-only two minor releases later.\n",
      "  ax.set_yticklabels(\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp/ipykernel_1128/2350893480.py:44: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cumulative_dist(\n",
    "    list(map(lambda x : x.item(), baseline_observations)),\n",
    "    stabilized_observations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b0a44-d47c-4009-8ad3-d5b7a5fd0d3e",
   "metadata": {},
   "source": [
    "Save the results for later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d39a0de-10ae-4232-9b73-a2cedfccff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    f\"inception_tr_distribution_result_{int(time.time()) % 1000000:06}.pt\",\n",
    "    \"wb\"\n",
    ") as file_obj:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"baseline\" : baseline_observations,\n",
    "            \"stabilized\" : stabilized_observations\n",
    "        }, file_obj\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
